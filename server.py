import io
import os
import base64
import logging
import traceback
from typing import List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from PIL import Image, ImageOps

import torch
import torchvision.transforms as T
import torch.nn.functional as F

# â˜… ëª¨ë¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
from film_unet import FiLM_UNet

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "film_unet_best.pth"

logger = logging.getLogger("uvicorn.error")
model = None 

# â˜… í•µì‹¬ ìˆ˜ì •: ê³ ì •ëœ 256 ë¦¬ì‚¬ì´ì¦ˆ ì œê±°í•¨ (ë™ì ìœ¼ë¡œ ì²˜ë¦¬í•  ê²ƒì„)
# MAX_SIZE: ë„ˆë¬´ í° ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì„œë²„ ë ‰ ê±¸ë¦¬ë‹ˆê¹Œ ì´ ì •ë„ë¡œë§Œ ì¤„ì„ (í™”ì§ˆ ìœ ì§€ìš©)
MAX_SIZE = 1024 

# -----------------------------
# ëª¨ë¸ ë¡œë“œ
# -----------------------------
def get_model() -> FiLM_UNet:
    global model
    if model is None:
        try:
            logger.info(f"ğŸš€ ëª¨ë¸ ë¡œë“œ ì‹œì‘ (Device: {DEVICE})")
            # ê²½ëŸ‰í™” ëª¨ë¸ (base=16)
            m = FiLM_UNet(user_dim=4, base=16)
            state = torch.load(MODEL_PATH, map_location=DEVICE)
            m.load_state_dict(state)
            m.to(DEVICE)
            m.eval()
            model = m
            logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    return model

# -----------------------------
# ìš”ì²­ ë°ì´í„° êµ¬ì¡°
# -----------------------------
class CorrectionRequest(BaseModel):
    image: str              # base64
    user_vec: List[float]   # [p, d, t, delta]

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

@app.on_event("startup")
def on_startup():
    get_model()

# -----------------------------
# â˜… í™”ì§ˆ ì‚´ë¦¬ëŠ” í•µì‹¬ í•¨ìˆ˜
# -----------------------------
def smart_resize(img_tensor):
    """
    U-Netì€ ì´ë¯¸ì§€ í¬ê¸°ê°€ 16ì˜ ë°°ìˆ˜ì—¬ì•¼ ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤. (Pooling ë•Œë¬¸)
    ì´ë¯¸ì§€ë¥¼ ê°•ì œë¡œ 256ìœ¼ë¡œ ì¤„ì´ëŠ” ëŒ€ì‹ , ê°€ì¥ ê°€ê¹Œìš´ 16ì˜ ë°°ìˆ˜ë¡œ ì‚´ì§ë§Œ ë‹¤ë“¬ìŠµë‹ˆë‹¤.
    """
    _, _, h, w = img_tensor.shape
    
    # 1. ë„ˆë¬´ í¬ë©´ ì¤„ì´ê¸° (ë©”ëª¨ë¦¬ ë³´í˜¸)
    if max(h, w) > MAX_SIZE:
        scale = MAX_SIZE / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)
        img_tensor = F.interpolate(img_tensor, size=(new_h, new_w), mode='bilinear', align_corners=False)
        _, _, h, w = img_tensor.shape # ì¤„ì–´ë“  í¬ê¸° ì—…ë°ì´íŠ¸

    # 2. 16ì˜ ë°°ìˆ˜ë¡œ ë§ì¶”ê¸° (Padding)
    # ì˜ˆ: 1000px -> 1008px (ê²€ì€ í…Œë‘ë¦¬ ì‚´ì§ ì¶”ê°€í•´ì„œ ëª¨ë¸ ì˜¤ë¥˜ ë°©ì§€)
    pad_h = (16 - (h % 16)) % 16
    pad_w = (16 - (w % 16)) % 16
    
    if pad_h > 0 or pad_w > 0:
        # (ì™¼ìª½, ì˜¤ë¥¸ìª½, ìœ„, ì•„ë˜) ìˆœì„œë¡œ íŒ¨ë”©
        img_tensor = F.pad(img_tensor, (0, pad_w, 0, pad_h), mode='reflect')
    
    return img_tensor, h, w  # ì›ë³¸ ë†’ì´/ë„ˆë¹„ ë°˜í™˜ (ë‚˜ì¤‘ì— ì˜ë¼ë‚´ê¸° ìœ„í•´)

# -----------------------------
# /correct ì—”ë“œí¬ì¸íŠ¸
# -----------------------------
@app.post("/correct")
def correct_color(req: CorrectionRequest):
    try:
        m = get_model()

        # 1. Base64 -> PIL -> Tensor
        try:
            img_bytes = base64.b64decode(req.image)
            pil_img = Image.open(io.BytesIO(img_bytes))
            pil_img = ImageOps.exif_transpose(pil_img).convert("RGB")
        except Exception as e:
            raise HTTPException(status_code=400, detail="Image decode fail")

        # 2. í…ì„œ ë³€í™˜ (0~1)
        # â˜… ì—¬ê¸°ì„œ ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆë¥¼ í•˜ì§€ ì•Šê³  ì›ë³¸ ê·¸ëŒ€ë¡œ í…ì„œë¡œ ë°”ê¿‰ë‹ˆë‹¤.
        x = T.ToTensor()(pil_img).unsqueeze(0).to(DEVICE) # (1, 3, H, W)

        # 3. â˜… ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ (í™”ì§ˆ ë³´ì¡´ì˜ í•µì‹¬!)
        # 256ìœ¼ë¡œ êµ¬ê²¨ë„£ì§€ ì•Šê³ , ì›ë˜ í¬ê¸° ê·¼ì²˜ì—ì„œ 16ë°°ìˆ˜ë§Œ ë§ì¶¥ë‹ˆë‹¤.
        x_padded, orig_h, orig_w = smart_resize(x)
        
        user_vec = torch.tensor([req.user_vec], dtype=torch.float32, device=DEVICE)

        # 4. ëª¨ë¸ ì‹¤í–‰
        with torch.no_grad():
            y = m(x_padded, user_vec)

        # 5. íŒ¨ë”© ì œê±° (ì›ë˜ í¬ê¸°ë¡œ ë³µêµ¬)
        y = y[:, :, :orig_h, :orig_w]

        # 6. ê²°ê³¼ ë³€í™˜ ë° ì „ì†¡
        y = y.squeeze(0).cpu().clamp(0, 1)
        out_pil = T.ToPILImage()(y)

        # ë””ë²„ê¹…ìš© ì €ì¥ (ì„œë²„ í´ë” í™•ì¸í•´ë³´ì„¸ìš” - í™”ì§ˆ ì¢‹ì•„ì¡ŒëŠ”ì§€)
        out_pil.save("server_result_high_res.png")

        buf = io.BytesIO()
        out_pil.save(buf, format="JPEG", quality=95) # ê³ í™”ì§ˆ ì €ì¥
        out_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {orig_w}x{orig_h}")
        return {"corrected_image": out_b64}

    except Exception as e:
        logger.error(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=False)