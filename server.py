import io
import os
import base64
import logging
import traceback
from typing import List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from PIL import Image, ImageOps

import torch
import torchvision.transforms as T
import torch.nn.functional as F

# â˜… ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
from film_unet import FiLM_UNet

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "film_unet_best.pth"

logger = logging.getLogger("uvicorn.error")
model = None

# â˜… í•µì‹¬ ì„¤ì •: í™”ì§ˆ ì œí•œì„ 1024pxë¡œ ë„‰ë„‰í•˜ê²Œ ë‘  (256 ì•„ë‹˜!)
MAX_SIZE = 1024  # ë„ˆë¬´ í° ì´ë¯¸ì§€ëŠ” ì„œë²„ê°€ í„°ì§ˆ ìˆ˜ ìˆì–´ì„œ ì´ ì •ë„ë¡œ ì œí•œ


# -----------------------------
# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# -----------------------------
def get_model() -> FiLM_UNet:
    global model
    if model is None:
        try:
            logger.info(f"ğŸš€ ëª¨ë¸ ë¡œë“œ ì‹œì‘ (Device: {DEVICE})")

            # â˜… ê²½ëŸ‰í™” ëª¨ë¸ ìƒì„± (base=16 í™•ì¸!)
            m = FiLM_UNet(user_dim=4, base=16)

            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"{MODEL_PATH} not found")

            # ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ
            state = torch.load(MODEL_PATH, map_location=DEVICE)
            m.load_state_dict(state)

            m.to(DEVICE)
            m.eval()
            model = m
            logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    return model


# -----------------------------
# ìš”ì²­ ë°ì´í„° êµ¬ì¡° (Pydantic)
# -----------------------------
class CorrectionRequest(BaseModel):
    image: str              # base64 string (data:image/...;base64, ... ë„ í—ˆìš©)
    user_vec: List[float]   # [protan, deutan, tritan, deltaE_or_severity]


# -----------------------------
# FastAPI ì•± ì„¤ì •
# -----------------------------
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
def on_startup():
    get_model()  # ì„œë²„ ì¼œì§ˆ ë•Œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ


# -----------------------------
# user_vec ì •ê·œí™” í•¨ìˆ˜
# -----------------------------
def normalize_user_vec(raw_vec: List[float]) -> List[float]:
    """
    í•™ìŠµí•  ë•Œ ë§ˆì§€ë§‰ ê°’ì€ 0~1 severity(Î±)ë¡œ ì¼ë‹¤ê³  ê°€ì •.
    ì•±ì—ì„œ 0~100 ê°™ì€ deltaEë¡œ ë³´ëƒˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ 0~1ë¡œ ìŠ¤ì¼€ì¼ë§í•´ ì¤Œ.
    """
    if len(raw_vec) != 4:
        raise ValueError("user_vec length must be 4")

    p, d, t, s = raw_vec

    # sê°€ 1ë³´ë‹¤ í¬ë©´ deltaE ëŠë‚Œì´ë¼ê³  ë³´ê³  0~1ë¡œ ì¶•ì†Œ
    if s > 1.0:
        s = max(0.0, min(s / 100.0, 1.0))
    else:
        s = max(0.0, min(s, 1.0))

    return [float(p), float(d), float(t), float(s)]


# -----------------------------
# â˜… í™”ì§ˆ ì‚´ë¦¬ëŠ” í•µì‹¬ í•¨ìˆ˜ (Smart Resize)
# -----------------------------
def smart_resize(img_tensor: torch.Tensor):
    """
    ì´ë¯¸ì§€ë¥¼ 256ìœ¼ë¡œ êµ¬ê²¨ ë„£ì§€ ì•Šê³ , ì›ë³¸ í¬ê¸°ë¥¼ ìµœëŒ€í•œ ì‚´ë¦½ë‹ˆë‹¤.
    ë‹¨, U-Netì´ ì‘ë™í•˜ë ¤ë©´ ê°€ë¡œ/ì„¸ë¡œê°€ 16ì˜ ë°°ìˆ˜ì—¬ì•¼ í•˜ë¯€ë¡œ
    ì´ë¯¸ì§€ë¥¼ ëŠ˜ë¦¬ì§€ ì•Šê³  ê°€ì¥ìë¦¬ì— ì‚´ì§ 'ì—¬ë°±(Padding)'ì„ ì¤ë‹ˆë‹¤.

    ë°˜í™˜í•˜ëŠ” (valid_h, valid_w)ëŠ”
    - MAX_SIZEë¡œ í•œ ë²ˆ ì¤„ì¸ ë’¤
    - padding ë„£ê¸° ì§ì „ì˜ 'ì‹¤ì œ ìœ íš¨ ì˜ì—­ í¬ê¸°' ì…ë‹ˆë‹¤.
    """
    _, _, h, w = img_tensor.shape

    # 1. ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´(ì˜ˆ: 3000px) ì ë‹¹íˆ(1024px) ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ë³´í˜¸
    if max(h, w) > MAX_SIZE:
        scale = MAX_SIZE / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)
        img_tensor = F.interpolate(
            img_tensor,
            size=(new_h, new_w),
            mode="bilinear",
            align_corners=False,
        )
        _, _, h, w = img_tensor.shape  # ì¤„ì–´ë“  í¬ê¸°ë¡œ ì—…ë°ì´íŠ¸

    # 2. 16ì˜ ë°°ìˆ˜ë¡œ ë§ì¶”ê¸° (Padding)
    pad_h = (16 - (h % 16)) % 16
    pad_w = (16 - (w % 16)) % 16

    if pad_h > 0 or pad_w > 0:
        # (ì™¼ìª½, ì˜¤ë¥¸ìª½, ìœ„, ì•„ë˜) ìˆœì„œë¡œ íŒ¨ë”© ì ìš©
        img_tensor = F.pad(img_tensor, (0, pad_w, 0, pad_h), mode="reflect")

    return img_tensor, h, w  # íŒ¨ë”© ë¶™ì´ê¸° ì „ì˜ 'ìœ íš¨ ì˜ì—­ í¬ê¸°' ë°˜í™˜


# -----------------------------
# /correct ì—”ë“œí¬ì¸íŠ¸
# -----------------------------
@app.post("/correct")
def correct_color(req: CorrectionRequest):
    try:
        m = get_model()

        # 0. user_vec ì •ê·œí™”
        try:
            norm_vec = normalize_user_vec(req.user_vec)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"user_vec error: {e}")

        # 1. Base64 -> PIL -> Tensor ë³€í™˜
        try:
            b64_str = req.image
            # data:image/png;base64,xxxx í˜•ì‹ì´ë©´ ì½¤ë§ˆ ë’¤ë§Œ ì‚¬ìš©
            if "," in b64_str:
                b64_str = b64_str.split(",", 1)[1]

            img_bytes = base64.b64decode(b64_str)
            pil_img = Image.open(io.BytesIO(img_bytes))
            pil_img = ImageOps.exif_transpose(pil_img).convert("RGB")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Image decode fail: {e}")

        # 2. í…ì„œ ë³€í™˜ (0~1 ë²”ìœ„)
        # â˜… ì£¼ì˜: ì—¬ê¸°ì„œ T.Resize(256)ì„ ì ˆëŒ€ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤! ì›ë³¸ ê·¸ëŒ€ë¡œ ë³€í™˜.
        x = T.ToTensor()(pil_img).unsqueeze(0).to(DEVICE)  # (1, 3, H, W)

        # 3. â˜… ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ ì ìš©
        x_padded, valid_h, valid_w = smart_resize(x)

        user_vec_tensor = torch.tensor(
            [norm_vec], dtype=torch.float32, device=DEVICE
        )

        # 4. ëª¨ë¸ ì‹¤í–‰ (Inference)
        with torch.no_grad():
            y = m(x_padded, user_vec_tensor)

        # 5. íŒ¨ë”© ì œê±° (resize í›„ ìœ íš¨ ì˜ì—­ë§Œ ê¹”ë”í•˜ê²Œ ì˜¤ë ¤ë‚´ê¸°)
        y = y[:, :, :valid_h, :valid_w]

        # 6. ê²°ê³¼ ë³€í™˜ ë° ì „ì†¡
        y = y.squeeze(0).cpu().clamp(0, 1)
        out_pil = T.ToPILImage()(y)

        # (ë””ë²„ê¹…ìš©) ì„œë²„ ì»´í“¨í„° í´ë”ì— ê²°ê³¼ íŒŒì¼ ì €ì¥
        # out_pil.save("server_result_check.png")

        buf = io.BytesIO()
        out_pil.save(buf, format="JPEG", quality=95)  # ê³ í™”ì§ˆ JPEG ì €ì¥
        out_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        logger.info(
            f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {valid_w}x{valid_h} (UserVec: {norm_vec}, Device: {DEVICE})"
        )
        return {"corrected_image": out_b64}

    except HTTPException:
        # ì´ë¯¸ ì ì ˆí•œ status ì½”ë“œë¡œ ì˜¬ë¦° ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ í†µê³¼
        raise
    except Exception as e:
        tb = traceback.format_exc()
        logger.error(f"Error in /correct: {e}\n{tb}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    # 0.0.0.0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì™¸ë¶€(ì•±)ì—ì„œ ì ‘ì† ê°€ëŠ¥í•˜ê²Œ í•¨
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=False)
